---
phase: 01-product-definition-and-tech-decisions
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/PRD.md
autonomous: true

must_haves:
  truths:
    - "An engineer reading only docs/PRD.md can describe the full pipeline lifecycle (intake through serving), identify all personas, and explain the monitoring requirements without consulting any other document"
    - "Every pipeline phase (intake, parsing, enrichment, storage, serving) has a Mermaid data flow diagram showing typed inputs, transformations, and typed outputs"
    - "The tenant lifecycle state machine has explicit states (PENDING, PROVISIONING, ACTIVE, SUSPENDED, DEPROVISIONING, DEPROVISIONED, FAILED), transitions with triggers, pre-conditions, actions, audit events, and rollback capabilities"
    - "Every API endpoint group (intake, query, admin, audit) has HTTP method, path, request schema, response schema, error responses, auth requirements, and rate limits"
    - "Monitoring requirements specify concrete metric names, alert conditions, severity levels, and log schema — not just 'use Prometheus'"
  artifacts:
    - path: "docs/PRD.md"
      provides: "Complete zero-shot Product Requirements Document for the Frostbyte multi-tenant ETL pipeline"
      contains:
        - "Executive Summary with what/why/who/how"
        - "Pipeline phase specifications with data flow diagrams for all 5 phases"
        - "Tenant lifecycle state machine with transition table"
        - "Monitoring and observability specification"
        - "API contract specification with request/response schemas and error envelope"
  key_links:
    - from: "docs/PRD.md section 2 (Pipeline Phases)"
      to: "docs/PRD.md section 5 (API Contracts)"
      via: "Each pipeline phase emits audit events referenced in the API audit endpoints"
      pattern: "audit event types defined in pipeline phases appear in audit API query parameters"
    - from: "docs/PRD.md section 3 (Tenant Lifecycle)"
      to: "docs/PRD.md section 5 (API Contracts — Admin)"
      via: "Tenant state transitions map to admin API endpoints"
      pattern: "each state transition has a corresponding admin API endpoint"
    - from: "docs/PRD.md section 4 (Monitoring)"
      to: "docs/PRD.md section 2 (Pipeline Phases)"
      via: "Metrics and alerts reference specific pipeline phase events"
      pattern: "metric names reference pipeline phases (intake, parse, policy, embed, serve)"
---

<objective>
Create the complete, self-contained Product Requirements Document (PRD) for the Frostbyte multi-tenant ETL pipeline.

Purpose: This PRD is the single authoritative reference for what the system does, who it serves, how data flows through it, how tenants are managed, what is monitored, and what API contracts exist. Every subsequent phase (isolation architecture, audit design, implementation plans, deployment specs, team docs) references this document. It must be specific enough that an engineer who has never seen the codebase can describe the full system by reading only this document.

Output: `docs/PRD.md` — a comprehensive Markdown document with 5 sections mapping to requirements PRD-01 through PRD-05.
</objective>

<execution_context>
@/Users/coreyalejandro/.claude/get-shit-done/workflows/execute-plan.md
@/Users/coreyalejandro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Source materials — read ALL of these before writing. Synthesize, do not duplicate

@docs/ETL_PIPELINE_PROPOSAL.md
@docs/CUSTOMER_JOURNEY_MAP.md
@docs/THREAT_MODEL_SAFETY.md
@.planning/research/ARCHITECTURE.md
@.planning/research/FEATURES.md
@.planning/research/PITFALLS.md
@.planning/phases/01-product-definition-and-tech-decisions/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write the zero-shot PRD (docs/PRD.md)</name>
  <files>docs/PRD.md</files>
  <action>
Read ALL source materials listed in the context section BEFORE writing. The PRD synthesizes and formalizes information from these sources — it does NOT copy-paste prose from them. Where existing artifacts describe things informally, the PRD formalizes them with schemas, diagrams, state machines, and contracts.

Create `docs/PRD.md` with exactly these 5 sections (each maps to a requirement):

**Section 1: Executive Summary (PRD-01)**

Synthesize from ETL_PIPELINE_PROPOSAL.md section 0 and CUSTOMER_JOURNEY_MAP.md:

- **What**: One paragraph describing the multi-tenant document ETL pipeline — "document in, structure out, stored in DB and vector" with per-tenant isolation, dual-mode operation (online API + offline air-gapped Docker), and full audit trails.
- **Why**: Business justification — Frostbyte serves regulated industries where data sovereignty is non-negotiable, documents are untrusted inputs, and retrieval provenance must be inspectable. Reference Dana's pain points P1-P5 from the journey map as the problems this solves.
- **Who**: Four personas with their roles and primary interactions:
  1. Dana (Vendor Data Operations Lead) — submits document batches, reads acceptance reports, runs test queries
  2. Frode (Frostbyte Platform Owner) — provisions tenants, monitors pipeline health, manages kill-switches
  3. Engineers — implement pipeline phases, debug failures, extend the system
  4. Auditors — query audit logs, export compliance evidence, verify provenance chains
- **How**: Architectural overview paragraph describing the three-tier architecture (control plane / data plane / audit plane) from ARCHITECTURE.md. Keep this to 3-4 sentences — the detail comes in later sections. Include a top-level Mermaid diagram showing the three planes and their relationships (synthesize from diagrams/architecture.mmd and diagrams/tenancy.mmd).
- **Deployment Modes**: Two paragraphs — one for online mode (Hetzner Cloud, OpenRouter embeddings, centralized audit), one for offline mode (Docker Compose, Nomic embed-text, local audit). Emphasize that the pipeline code is identical; only infrastructure provisioning and embedding routing differ.
- **Anti-Features**: A table listing the 6 anti-features from FEATURES.md (AF-1 through AF-6) with "Feature" and "Why Excluded" columns. This sets boundaries that prevent scope creep in downstream phases.

**Section 2: Pipeline Phase Specifications (PRD-02)**

For EACH of the 5 pipeline phases, create a subsection with:

Phase A — Intake Gateway (Trust Boundary):

- **Inputs**: Vendor batch uploads (HTTPS/SFTP) with JSON manifest containing file list, checksums, tenant credentials.
- **Transformations**: Manifest validation -> per-file processing (MIME allowlist check -> size check -> checksum verification -> ClamAV malware scan -> write to object store -> generate intake receipt -> emit audit event -> enqueue parse job) -> return batch receipt.
- **Outputs**: Intake receipt JSON (define the schema using the intake receipt schema from 01-RESEARCH.md: receipt_id, tenant_id, batch_id, file_id, original_filename, mime_type, size_bytes, sha256, scan_result, received_at, storage_path, status). Batch receipt JSON (batch_id, file_count, accepted, rejected, quarantined).
- **Data flow diagram**: Mermaid flowchart showing the full intake request flow from ARCHITECTURE.md "Intake Gateway Design" section, formalized with typed inputs/outputs at each step.
- **Error handling**: What happens on manifest mismatch (reject batch), checksum failure (reject file), MIME rejection (reject file with reason), malware detection (quarantine file), size exceeded (reject file).
- **Audit events emitted**: DOCUMENT_INGESTED (per file), BATCH_RECEIVED (per batch), DOCUMENT_REJECTED (per rejection), DOCUMENT_QUARANTINED (per quarantine).

Phase B — Document Normalization (Parsing):

- **Inputs**: Raw document files from object store (PDF, DOCX, XLSX, TXT, CSV, PNG, TIFF).
- **Transformations**: Docling stage (layout-aware conversion: tables, figures, sections, reading order, offsets) -> Unstructured stage (partitioning, chunking by_title strategy, metadata enrichment, stable chunk ID generation) -> canonical JSON assembly (merge structure + elements, assign deterministic chunk IDs via hash(doc_id + page + start_offset + end_offset), record lineage).
- **Outputs**: Canonical Structured Document JSON (define the schema: doc_id, file_id, tenant_id, sections[], tables[], figures[], reading_order[], lineage: {raw_sha256, docling_version, unstructured_version, parse_timestamp}, chunks[]: {chunk_id, text, page, start_char, end_char, element_type, metadata}).
- **Data flow diagram**: Mermaid flowchart showing the two-stage parsing from ARCHITECTURE.md "Document Processing Pipeline".
- **Error handling**: Parse failure per file (mark failed, log reason, include in acceptance report), partial extraction (flag dropped content with reason), OCR fallback for scanned documents.
- **Audit events emitted**: DOCUMENT_PARSED (success), DOCUMENT_PARSE_FAILED (with reason), CONTENT_DROPPED (per dropped element).

Phase C — Policy Gates and Enrichment:

- **Inputs**: Canonical Structured Document JSON from Phase B.
- **Transformations**: Gate 1: PII/PHI detection (NER-based scan -> configurable per-tenant action: REDACT/FLAG/BLOCK) -> Gate 2: Document classification (rule-based first, ML-assisted second -> categories: contract, invoice, SOP, policy, correspondence, legal_filing, other) -> Gate 3: Injection defense (pattern scanner for known injection phrases + homoglyph detection + invisible char detection -> heuristic scorer 0.0-1.0 -> action: <0.3 PASS, 0.3-0.7 FLAG, >0.7 QUARANTINE) -> Deterministic chunk ID assignment + metadata enrichment.
- **Outputs**: Policy-enriched chunks (chunk_id, doc_id, text, metadata: {pii_scan_result, pii_types_found[], pii_action_taken, classification, classification_confidence, classifier_version, injection_score, injection_patterns_matched[], injection_action_taken}, offsets: {page, start_char, end_char}).
- **Data flow diagram**: Mermaid flowchart showing the three sequential gates from ARCHITECTURE.md "Policy Gate Patterns".
- **Error handling**: PII BLOCK action quarantines entire document. Injection QUARANTINE prevents embedding. Classification low-confidence routes to review queue.
- **Audit events emitted**: POLICY_GATE_PASSED (per gate per document), POLICY_GATE_FAILED (per gate per document), DOCUMENT_QUARANTINED (with reason), PII_DETECTED (with types, no content).
- **CRITICAL**: Emphasize that all three gates run BEFORE embedding. Malicious or sensitive content must never reach the vector store. Reference ARCHITECTURE.md anti-pattern #2.

Phase D — Embedding and Storage:

- **Inputs**: Policy-approved chunks from Phase C.
- **Transformations**: Embed chunks (online: OpenRouter text-embedding-3-small with dimensions=768; offline: Nomic embed-text v1.5 at native 768d) -> Record model name + version per vector -> Write to three stores (object store: normalized artifacts; relational DB: chunk metadata, lineage, job state; vector store: embedding + chunk_id + metadata filter fields) -> Verify write integrity (compare written hash with computed hash).
- **Outputs**: Vectors in Qdrant (tenant-scoped collection), metadata rows in PostgreSQL, normalized artifacts in MinIO. Index metadata record: {chunk_id, doc_id, tenant_id, embed_model, embed_version, embed_dimensions, vector_sha256, indexed_at}.
- **Data flow diagram**: Mermaid flowchart showing the three-store write pattern from ARCHITECTURE.md "Storage Architecture".
- **Error handling**: Embedding API failure (retry with exponential backoff, max 3), partial write (transaction rollback across stores or compensating action), dimension mismatch assertion failure (halt and alert).
- **Audit events emitted**: DOCUMENT_EMBEDDED (per document), INDEX_WRITTEN (per chunk batch), EMBEDDING_FAILED (with reason).
- **IMPORTANT**: Both modes lock to 768 dimensions. This enables cross-mode vector compatibility. Document that switching embedding models requires full re-indexing.

Phase E — Serving (RAG Retrieval):

- **Inputs**: Query request: {tenant_id, query_text, top_k, filters: {classification?, date_range?, doc_ids?}}.
- **Transformations**: Authenticate + authorize (JWT, tenant scope) -> Embed query (same model used for indexing, version must match) -> Vector search (Qdrant ANN search with metadata filters, return top_k chunk_ids with similarity scores) -> Fetch source slices (text from object store, metadata from relational DB, lineage) -> Build retrieval proof object -> Return response.
- **Outputs**: Retrieval response: {query_id, tenant_id, chunks: [{chunk_id, doc_id, text, page, offsets, similarity_score, embed_model, embed_version, source_sha256}], timestamp}. If generation is enabled: {answer, retrieval_proof, metadata} where every claim in the answer references a chunk_id.
- **Data flow diagram**: Mermaid flowchart showing the retrieval flow from ARCHITECTURE.md "Serving Layer".
- **Error handling**: Auth failure (401/403), no results (return empty with metadata), embedding model version mismatch (alert, degrade gracefully), vector store unavailable (503 with retry hint).
- **Audit events emitted**: RETRIEVAL_EXECUTED (per query, with chunk_ids returned, no content), GENERATION_EXECUTED (if generation enabled).
- **Cite-only-from-retrieval**: Every claim in a generated answer must reference a chunk_id from the retrieval proof. Flag or suppress ungrounded text. This is a hard architectural constraint per THREAT_MODEL_SAFETY.md control D.

**Section 3: Tenant Lifecycle Management (PRD-03)**

Create a formal state machine specification synthesizing from 01-RESEARCH.md "Pattern 3: Tenant Lifecycle State Machine" and ARCHITECTURE.md "Per-Tenant Provisioning Pattern":

- **State diagram**: Mermaid stateDiagram-v2 showing all states (PENDING, PROVISIONING, ACTIVE, SUSPENDED, DEPROVISIONING, DEPROVISIONED, FAILED) and all transitions.
- **State transition table**: For EACH transition, specify:
  | Transition | Trigger | Pre-conditions | Actions | Audit Event | Rollback |
  Use the transition table from 01-RESEARCH.md as the starting point but expand it to include:
  - ACTIVE -> ACTIVE (update_config): tenant configuration change, non-disruptive
  - FAILED -> PROVISIONING (retry): manual retry after fixing provisioning failure
  - FAILED -> DEPROVISIONING (abandon): clean up after unrecoverable failure
- **Kill-switch specification**: The ACTIVE -> SUSPENDED transition must be instant and reversible. Specify exactly what "instant" means: disable API routing (< 1s), pause all Celery jobs (drain queue), revoke tenant API keys (invalidate in gateway cache), emit TENANT_SUSPENDED audit event. Specify what "reversible" means: SUSPENDED -> ACTIVE restores routing, resumes jobs, issues new API keys.
- **Provisioning actions detail**: For the PENDING -> PROVISIONING -> ACTIVE path, list the exact provisioning sequence from ARCHITECTURE.md (create Hetzner project/token, provision compute, provision networking with firewall rules, provision storage with per-tenant credentials, provision secrets, configure DNS, register in tenant registry). Mark which steps are online-only vs. offline-equivalent.

**Section 4: Monitoring and Observability (PRD-04)**

Create a specification for monitoring, alerting, metrics, and logging. Do NOT just say "use Prometheus" — specify concrete requirements:

- **Job tracking**: Define the job status model (QUEUED -> PROCESSING -> COMPLETED | FAILED) with per-stage granularity. Specify which API endpoint Dana uses to check batch status (reference Section 5 API contracts). Define the job status response schema.
- **Metrics specification**: Define concrete metric names and types:
  - `frostbyte_intake_files_total` (counter, labels: tenant_id, status=[accepted|rejected|quarantined])
  - `frostbyte_parse_duration_seconds` (histogram, labels: tenant_id, parser=[docling|unstructured])
  - `frostbyte_policy_gate_results_total` (counter, labels: tenant_id, gate=[pii|classification|injection], result=[pass|flag|quarantine])
  - `frostbyte_embed_duration_seconds` (histogram, labels: tenant_id, model=[openrouter|nomic])
  - `frostbyte_retrieval_latency_seconds` (histogram, labels: tenant_id)
  - `frostbyte_retrieval_results_total` (counter, labels: tenant_id, result_count_bucket)
  - `frostbyte_storage_bytes` (gauge, labels: tenant_id, store=[minio|postgres|qdrant])
  - `frostbyte_celery_queue_length` (gauge, labels: tenant_id, queue=[parse|policy|embed|index])
  - `frostbyte_tenant_state` (gauge, labels: tenant_id, state=[active|suspended|provisioning|...])
- **Alert conditions**: Define alerts with severity, condition, and action:
  - CRITICAL: Parse failure rate > 50% for any tenant in 15-minute window -> page on-call
  - CRITICAL: Tenant storage > 90% capacity -> alert ops + auto-throttle intake
  - HIGH: Celery dead-letter queue depth > 10 for any tenant -> alert ops
  - HIGH: Embedding API error rate > 10% in 5-minute window -> alert ops
  - MEDIUM: Intake rejection rate > 20% for any tenant in 1-hour window -> notify tenant admin
  - MEDIUM: Parse duration p95 > 5 minutes for any tenant -> investigate
  - LOW: Tenant batch submitted outside business hours -> log, no action
- **Log requirements**: All logs must be structured JSON via structlog. Required fields on every log line: timestamp, level, tenant_id (if applicable), request_id, component, message. Content fields (document text, PII, query text) must NEVER appear in logs. Logs are operational; audit events are compliance — they are separate systems with separate retention.
- **Dashboard requirements**: Per-tenant dashboard showing: batch status timeline, parse quality metrics, storage utilization, retrieval latency distribution, active alerts. Platform-wide dashboard showing: tenant count by state, aggregate throughput, error rates, resource utilization.

**Section 5: API Contract Specification (PRD-05)**

Define API contracts for four endpoint groups. For EACH endpoint, specify: HTTP method, path, request schema, success response schema, error responses (400, 401, 403, 404, 429, 500), auth requirements, rate limits.

Use the standard error envelope from 01-RESEARCH.md for all error responses:

```json
{
  "success": false,
  "error": {
    "code": "MACHINE_READABLE_CODE",
    "message": "Human-readable message",
    "details": [],
    "request_id": "req-abc123"
  }
}
```

**Intake API**:

- `POST /api/v1/ingest/{tenant_id}/batch` — Submit a document batch (multipart form: manifest JSON + files). Returns batch receipt.
- `GET /api/v1/ingest/{tenant_id}/batch/{batch_id}` — Get batch status (queued, processing, completed, failed with per-file breakdown).
- `GET /api/v1/ingest/{tenant_id}/receipt/{receipt_id}` — Get individual intake receipt.

**Query API**:

- `POST /api/v1/query/{tenant_id}/search` — RAG retrieval query. Request: {query_text, top_k, filters}. Response: retrieval proof with chunks.
- `GET /api/v1/query/{tenant_id}/document/{doc_id}` — Get document metadata and chunk list.
- `GET /api/v1/query/{tenant_id}/chunk/{chunk_id}` — Get individual chunk with source slice and lineage.

**Admin API**:

- `POST /api/v1/admin/tenants` — Create tenant (triggers provisioning).
- `GET /api/v1/admin/tenants/{tenant_id}` — Get tenant state and configuration.
- `PATCH /api/v1/admin/tenants/{tenant_id}` — Update tenant configuration.
- `POST /api/v1/admin/tenants/{tenant_id}/suspend` — Kill-switch (ACTIVE -> SUSPENDED).
- `POST /api/v1/admin/tenants/{tenant_id}/resume` — Resume (SUSPENDED -> ACTIVE).
- `POST /api/v1/admin/tenants/{tenant_id}/deprovision` — Begin deprovisioning.
- `GET /api/v1/admin/tenants` — List tenants with state filter.

**Audit API**:

- `GET /api/v1/audit/{tenant_id}/events` — Query audit events (filters: event_type, date_range, resource_id, resource_type). Paginated.
- `GET /api/v1/audit/{tenant_id}/events/{event_id}` — Get single audit event with full details.
- `POST /api/v1/audit/{tenant_id}/export` — Export audit events for date range as JSON Lines file. Returns download URL.
- `GET /api/v1/audit/{tenant_id}/chain/{resource_id}` — Get full provenance chain for a resource (document or chunk) — all events in lineage order.

For the auth model: All endpoints require a Bearer JWT token. The token contains `tenant_id` (for tenant-scoped endpoints) or `role: admin` (for admin endpoints). Audit API requires `role: auditor` or `role: admin`. Rate limits: intake 100 req/min per tenant, query 1000 req/min per tenant, admin 60 req/min global, audit 300 req/min per tenant.

**Document structure notes:**

- Use `#` for the document title, `##` for the 5 sections, `###` for subsections within each section.
- Every Mermaid diagram must be in a fenced code block with `mermaid` language tag.
- Every schema must be shown as a JSON example with field descriptions.
- Add a "Document Conventions" section at the top explaining requirement IDs (PRD-01 through PRD-05) and how they map to sections.
- Add a "Glossary" at the end defining: tenant, data plane, control plane, audit plane, intake receipt, canonical structured document, policy gate, retrieval proof, kill-switch, envelope pattern.
- Do NOT add a table of contents — the section headers serve as the ToC.

**What NOT to write:**

- Do not copy prose verbatim from ETL_PIPELINE_PROPOSAL.md. Synthesize and formalize.
- Do not include implementation details (specific library names, version numbers, Docker configurations). Those belong in the tech decisions document (Plan 01-02) and implementation plans (Phase 4+).
- Do not reference "see Phase 2 for isolation details" — the PRD is self-contained for its scope. Mention isolation requirements but do not attempt to fully specify isolation architecture (that is Phase 2's job).
- Do not include forward references to documents that do not yet exist.
  </action>
  <verify>
Verify the PRD satisfies all 5 success criteria from the roadmap. Use both objective checks and structural review:

**Objective checks (run these):**

- Count top-level sections: `grep -c "^## " docs/PRD.md` — expect 5+ (5 sections plus possible conventions/glossary)
- Count Mermaid diagrams: `grep -c "^\`\`\`mermaid" docs/PRD.md` — expect exactly 5 (one per pipeline phase) plus the architecture overview diagram
- Verify all 7 tenant states present: search for PENDING, PROVISIONING, ACTIVE, SUSPENDED, DEPROVISIONING, DEPROVISIONED, FAILED
- Verify line count: `wc -l docs/PRD.md` — expect >3000 lines
- Verify no ambiguous tech language: search for "choose between", "consider using", "evaluate" — expect 0 matches in decision context

**Structural review:**

1. Confirm all 4 personas are identified in Section 1 (Dana, Frode, Engineers, Auditors) with their roles.
2. Confirm each pipeline phase (intake, parsing, policy, embedding/storage, serving) has: inputs, transformations, outputs, data flow diagram, error handling, audit events.
3. Confirm transition table exists with columns: Transition, Trigger, Pre-conditions, Actions, Audit Event, Rollback.
4. Confirm every API endpoint has: HTTP method, path, request schema, response schema, error responses (400/401/403/404/429/500), auth, rate limits.
5. Confirm monitoring has concrete metric names (e.g., `frostbyte_intake_files_total`), alert conditions with severity/thresholds, and log schema requirements.
6. Confirm no implementation details leaked: no library version numbers, no Docker configurations in pipeline descriptions.
7. Confirm glossary exists and defines key terms.
8. Confirm anti-features table present in Section 1.
  </verify>

  <done>
docs/PRD.md exists with all 5 sections. An engineer reading only this document can describe the full pipeline lifecycle, identify all personas, explain the tenant lifecycle state machine, reference concrete API contracts, and understand monitoring requirements. No forward references to unwritten documents. No implementation details (library versions, Docker configs). All 5 data flow diagrams present. Error envelope consistent across all API endpoints. Glossary defines all key terms.
  </done>
</task>

</tasks>

<verification>
Phase 1 success criteria that this plan addresses:
1. [PRD-01] Engineer can describe full pipeline lifecycle from PRD alone -- verified by reading Section 1 (exec summary) + Section 2 (pipeline phases)
2. [PRD-02] Every pipeline phase has a data flow diagram -- verified by counting 5 Mermaid diagrams in Section 2
3. [PRD-03] Tenant lifecycle specified as implementable state machine -- verified by state diagram + transition table in Section 3
4. [PRD-04] Monitoring requirements with concrete metrics -- verified by metric names table + alert conditions in Section 4
5. [PRD-05] API contracts with schemas and error responses -- verified by endpoint definitions in Section 5
</verification>

<success_criteria>

- docs/PRD.md exists and is >3000 lines (comprehensive document covering 5 major sections)
- All 5 pipeline phases have Mermaid data flow diagrams with typed inputs/outputs
- Tenant lifecycle state machine has 7 states and a complete transition table
- API contracts cover 4 endpoint groups (intake, query, admin, audit) with full request/response schemas
- Monitoring section has concrete metric names, alert conditions with thresholds, and log field requirements
- No forward references to unwritten documents
- No implementation details (version numbers, Docker configs, specific library names in pipeline descriptions)
- Glossary defines all key terms
- Anti-features table present
</success_criteria>

<output>
After completion, create `.planning/phases/01-product-definition-and-tech-decisions/01-01-SUMMARY.md`
</output>
